{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7efdcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from category_encoders import TargetEncoder\n",
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "\n",
    "data = pd.read_csv('clean_data.csv')\n",
    "# Define the desired age groups\n",
    "desired_age_groups = [\n",
    "    '10-14 years',\n",
    "    '15-19 years',\n",
    "    '20-24 years',\n",
    "    '25-29 years',\n",
    "    '30-34 years',\n",
    "    '35-39 years',\n",
    "    '40-44 years',\n",
    "    '45-49 years',\n",
    "    '50-54 years',\n",
    "    '55-59 years',\n",
    "    '60-64 years',\n",
    "    '65-69 years',\n",
    "    '70-74 years',\n",
    "    '75-79 years',\n",
    "    '80+ years'\n",
    "]\n",
    "# Filter the DataFrame\n",
    "data = data[data['age_group'].isin(desired_age_groups)]\n",
    "\n",
    "# Encode 'gender'\n",
    "le_sex = LabelEncoder()\n",
    "data['gender_enc'] = le_sex.fit_transform(data['gender'])\n",
    "\n",
    "# Encode 'age_group'\n",
    "ord_age = OrdinalEncoder(categories=[desired_age_groups])\n",
    "data['age_enc'] = ord_age.fit_transform(data[['age_group']]).astype(int)\n",
    "\n",
    "# drop country_code\n",
    "data = data.drop(['gender', 'age_group', 'country_code'], axis=1)\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "y = data['suicide_rate/100k']\n",
    "X = data.drop(['suicide_rate/100k'], axis=1)\n",
    "\n",
    "# Split into training (80%) and test (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "# ---------------------- Target Encoding with K-Fold CV ----------------------\n",
    "\n",
    "# (a) Create an empty Series to collect fold-wise encodings\n",
    "country_te_train = pd.Series(index=X_train.index, dtype=float)\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "for tr_idx, val_idx in kf.split(X_train):\n",
    "    X_tr, X_val = X_train.iloc[tr_idx], X_train.iloc[val_idx]\n",
    "    y_tr = y_train.iloc[tr_idx]\n",
    "    \n",
    "    te_fold = ce.TargetEncoder(cols=['country_name'])\n",
    "    te_fold.fit(X_tr[['country_name']], y_tr)\n",
    "    \n",
    "    country_te_train.iloc[val_idx] = (\n",
    "        te_fold.transform(X_val[['country_name']])['country_name']\n",
    "    ).values\n",
    "\n",
    "# (b) Fit a final encoder on *all* training data, for the test set\n",
    "final_te = ce.TargetEncoder(cols=['country_name'])\n",
    "final_te.fit(X_train[['country_name']], y_train)\n",
    "country_te_test = final_te.transform(X_test[['country_name']])['country_name'].values\n",
    "\n",
    "# (c) Drop the raw 'country_name' feature and insert the encoded versions\n",
    "X_train_enc = X_train.drop(columns=['country_name']).copy()\n",
    "X_train_enc['country_te'] = country_te_train\n",
    "\n",
    "X_test_enc = X_test.drop(columns=['country_name']).copy()\n",
    "X_test_enc['country_te'] = country_te_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75be2768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 10-Fold cross-validation with PCA...\n",
      "\n",
      "=== Cross-validating KNN ===\n",
      "Training fold 1/10 for KNN...\n",
      "Fold 1 - MAE: 1.8758, MSE: 18.7295, RMSE: 4.3278\n",
      "Training fold 2/10 for KNN...\n",
      "Fold 2 - MAE: 1.8218, MSE: 16.6161, RMSE: 4.0763\n",
      "Training fold 3/10 for KNN...\n",
      "Fold 3 - MAE: 1.8416, MSE: 17.5514, RMSE: 4.1894\n",
      "Training fold 4/10 for KNN...\n",
      "Fold 4 - MAE: 1.8735, MSE: 18.1141, RMSE: 4.2561\n",
      "Training fold 5/10 for KNN...\n",
      "Fold 5 - MAE: 1.8417, MSE: 17.5317, RMSE: 4.1871\n",
      "Training fold 6/10 for KNN...\n",
      "Fold 6 - MAE: 1.8183, MSE: 17.3824, RMSE: 4.1692\n",
      "Training fold 7/10 for KNN...\n",
      "Fold 7 - MAE: 1.8659, MSE: 17.7283, RMSE: 4.2105\n",
      "Training fold 8/10 for KNN...\n",
      "Fold 8 - MAE: 1.8124, MSE: 16.1701, RMSE: 4.0212\n",
      "Training fold 9/10 for KNN...\n",
      "Fold 9 - MAE: 1.8229, MSE: 18.3373, RMSE: 4.2822\n",
      "Training fold 10/10 for KNN...\n",
      "Fold 10 - MAE: 1.7421, MSE: 14.8889, RMSE: 3.8586\n",
      "KNN Mean -> MAE: 1.8316, MSE: 17.3050, RMSE: 4.1578\n",
      "\n",
      "\n",
      "=== Cross-validating Random Forest ===\n",
      "Training fold 1/10 for Random Forest...\n",
      "Fold 1 - MAE: 1.3753, MSE: 8.5982, RMSE: 2.9323\n",
      "Training fold 2/10 for Random Forest...\n",
      "Fold 2 - MAE: 1.3954, MSE: 10.2325, RMSE: 3.1988\n",
      "Training fold 3/10 for Random Forest...\n",
      "Fold 3 - MAE: 1.4523, MSE: 11.7350, RMSE: 3.4256\n",
      "Training fold 4/10 for Random Forest...\n",
      "Fold 4 - MAE: 1.5032, MSE: 11.1428, RMSE: 3.3381\n",
      "Training fold 5/10 for Random Forest...\n",
      "Fold 5 - MAE: 1.4902, MSE: 10.7931, RMSE: 3.2853\n",
      "Training fold 6/10 for Random Forest...\n",
      "Fold 6 - MAE: 1.3751, MSE: 10.9923, RMSE: 3.3155\n",
      "Training fold 7/10 for Random Forest...\n",
      "Fold 7 - MAE: 1.5484, MSE: 11.1430, RMSE: 3.3381\n",
      "Training fold 8/10 for Random Forest...\n",
      "Fold 8 - MAE: 1.4566, MSE: 10.1386, RMSE: 3.1841\n",
      "Training fold 9/10 for Random Forest...\n",
      "Fold 9 - MAE: 1.3733, MSE: 10.3606, RMSE: 3.2188\n",
      "Training fold 10/10 for Random Forest...\n",
      "Fold 10 - MAE: 1.4647, MSE: 9.4865, RMSE: 3.0800\n",
      "Random Forest Mean -> MAE: 1.4434, MSE: 10.4623, RMSE: 3.2317\n",
      "\n",
      "\n",
      "=== Cross-validating Decision Tree ===\n",
      "Training fold 1/10 for Decision Tree...\n",
      "Fold 1 - MAE: 1.6708, MSE: 22.4519, RMSE: 4.7383\n",
      "Training fold 2/10 for Decision Tree...\n",
      "Fold 2 - MAE: 1.6676, MSE: 23.5119, RMSE: 4.8489\n",
      "Training fold 3/10 for Decision Tree...\n",
      "Fold 3 - MAE: 1.7990, MSE: 32.5940, RMSE: 5.7091\n",
      "Training fold 4/10 for Decision Tree...\n",
      "Fold 4 - MAE: 1.8047, MSE: 27.8818, RMSE: 5.2803\n",
      "Training fold 5/10 for Decision Tree...\n",
      "Fold 5 - MAE: 1.8499, MSE: 29.8651, RMSE: 5.4649\n",
      "Training fold 6/10 for Decision Tree...\n",
      "Fold 6 - MAE: 1.7379, MSE: 30.4867, RMSE: 5.5215\n",
      "Training fold 7/10 for Decision Tree...\n",
      "Fold 7 - MAE: 2.0526, MSE: 33.5209, RMSE: 5.7897\n",
      "Training fold 8/10 for Decision Tree...\n",
      "Fold 8 - MAE: 1.7382, MSE: 27.6461, RMSE: 5.2580\n",
      "Training fold 9/10 for Decision Tree...\n",
      "Fold 9 - MAE: 1.6730, MSE: 29.6430, RMSE: 5.4445\n",
      "Training fold 10/10 for Decision Tree...\n",
      "Fold 10 - MAE: 1.7946, MSE: 25.0545, RMSE: 5.0054\n",
      "Decision Tree Mean -> MAE: 1.7788, MSE: 28.2656, RMSE: 5.3061\n",
      "\n",
      "\n",
      "=== Cross-validating MLP ===\n",
      "Training fold 1/10 for MLP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maya2\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - MAE: 3.9998, MSE: 39.5200, RMSE: 6.2865\n",
      "Training fold 2/10 for MLP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maya2\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - MAE: 3.7455, MSE: 35.8340, RMSE: 5.9862\n",
      "Training fold 3/10 for MLP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maya2\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - MAE: 3.7775, MSE: 35.5034, RMSE: 5.9585\n",
      "Training fold 4/10 for MLP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maya2\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - MAE: 3.7604, MSE: 37.6861, RMSE: 6.1389\n",
      "Training fold 5/10 for MLP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maya2\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 - MAE: 3.6633, MSE: 33.9496, RMSE: 5.8266\n",
      "Training fold 6/10 for MLP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maya2\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 6 - MAE: 3.7756, MSE: 34.5119, RMSE: 5.8747\n",
      "Training fold 7/10 for MLP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maya2\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 7 - MAE: 3.8016, MSE: 35.1606, RMSE: 5.9296\n",
      "Training fold 8/10 for MLP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maya2\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 8 - MAE: 3.8003, MSE: 37.1312, RMSE: 6.0935\n",
      "Training fold 9/10 for MLP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maya2\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 9 - MAE: 3.7590, MSE: 34.6060, RMSE: 5.8827\n",
      "Training fold 10/10 for MLP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maya2\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10 - MAE: 3.7204, MSE: 33.8016, RMSE: 5.8139\n",
      "MLP Mean -> MAE: 3.7803, MSE: 35.7705, RMSE: 5.9791\n",
      "\n",
      "\n",
      "=== Cross-validating Linear Regression ===\n",
      "Training fold 1/10 for Linear Regression...\n",
      "Fold 1 - MAE: 11.1751, MSE: 291.7347, RMSE: 17.0802\n",
      "Training fold 2/10 for Linear Regression...\n",
      "Fold 2 - MAE: 11.0474, MSE: 283.6794, RMSE: 16.8428\n",
      "Training fold 3/10 for Linear Regression...\n",
      "Fold 3 - MAE: 11.1499, MSE: 297.9565, RMSE: 17.2614\n",
      "Training fold 4/10 for Linear Regression...\n",
      "Fold 4 - MAE: 11.3340, MSE: 301.8359, RMSE: 17.3734\n",
      "Training fold 5/10 for Linear Regression...\n",
      "Fold 5 - MAE: 11.1846, MSE: 295.1069, RMSE: 17.1787\n",
      "Training fold 6/10 for Linear Regression...\n",
      "Fold 6 - MAE: 11.0714, MSE: 282.2101, RMSE: 16.7991\n",
      "Training fold 7/10 for Linear Regression...\n",
      "Fold 7 - MAE: 10.8193, MSE: 281.9254, RMSE: 16.7906\n",
      "Training fold 8/10 for Linear Regression...\n",
      "Fold 8 - MAE: 10.8183, MSE: 270.9516, RMSE: 16.4606\n",
      "Training fold 9/10 for Linear Regression...\n",
      "Fold 9 - MAE: 11.3107, MSE: 316.8653, RMSE: 17.8007\n",
      "Training fold 10/10 for Linear Regression...\n",
      "Fold 10 - MAE: 11.0042, MSE: 288.7139, RMSE: 16.9916\n",
      "Linear Regression Mean -> MAE: 11.0915, MSE: 291.0980, RMSE: 17.0579\n",
      "\n",
      "\n",
      "=== Cross-validating Ridge Regression ===\n",
      "Training fold 1/10 for Ridge Regression...\n",
      "Fold 1 - MAE: 11.1750, MSE: 291.7349, RMSE: 17.0802\n",
      "Training fold 2/10 for Ridge Regression...\n",
      "Fold 2 - MAE: 11.0473, MSE: 283.6794, RMSE: 16.8428\n",
      "Training fold 3/10 for Ridge Regression...\n",
      "Fold 3 - MAE: 11.1498, MSE: 297.9566, RMSE: 17.2614\n",
      "Training fold 4/10 for Ridge Regression...\n",
      "Fold 4 - MAE: 11.3340, MSE: 301.8356, RMSE: 17.3734\n",
      "Training fold 5/10 for Ridge Regression...\n",
      "Fold 5 - MAE: 11.1845, MSE: 295.1070, RMSE: 17.1787\n",
      "Training fold 6/10 for Ridge Regression...\n",
      "Fold 6 - MAE: 11.0714, MSE: 282.2099, RMSE: 16.7991\n",
      "Training fold 7/10 for Ridge Regression...\n",
      "Fold 7 - MAE: 10.8192, MSE: 281.9252, RMSE: 16.7906\n",
      "Training fold 8/10 for Ridge Regression...\n",
      "Fold 8 - MAE: 10.8183, MSE: 270.9516, RMSE: 16.4606\n",
      "Training fold 9/10 for Ridge Regression...\n",
      "Fold 9 - MAE: 11.3107, MSE: 316.8655, RMSE: 17.8007\n",
      "Training fold 10/10 for Ridge Regression...\n",
      "Fold 10 - MAE: 11.0042, MSE: 288.7139, RMSE: 16.9916\n",
      "Ridge Regression Mean -> MAE: 11.0914, MSE: 291.0980, RMSE: 17.0579\n",
      "\n",
      "\n",
      "=== Cross-validating Poly SVM ===\n",
      "Training fold 1/10 for Poly SVM...\n",
      "Fold 1 - MAE: 8.2677, MSE: 238.3854, RMSE: 15.4397\n",
      "Training fold 2/10 for Poly SVM...\n",
      "Fold 2 - MAE: 8.1250, MSE: 239.0778, RMSE: 15.4621\n",
      "Training fold 3/10 for Poly SVM...\n",
      "Fold 3 - MAE: 8.0776, MSE: 231.7209, RMSE: 15.2224\n",
      "Training fold 4/10 for Poly SVM...\n",
      "Fold 4 - MAE: 8.2608, MSE: 249.9128, RMSE: 15.8086\n",
      "Training fold 5/10 for Poly SVM...\n",
      "Fold 5 - MAE: 8.2398, MSE: 245.3722, RMSE: 15.6644\n",
      "Training fold 6/10 for Poly SVM...\n",
      "Fold 6 - MAE: 8.1499, MSE: 236.8095, RMSE: 15.3886\n",
      "Training fold 7/10 for Poly SVM...\n",
      "Fold 7 - MAE: 8.0174, MSE: 232.6311, RMSE: 15.2522\n",
      "Training fold 8/10 for Poly SVM...\n",
      "Fold 8 - MAE: 8.1954, MSE: 238.6584, RMSE: 15.4486\n",
      "Training fold 9/10 for Poly SVM...\n",
      "Fold 9 - MAE: 8.1282, MSE: 253.0484, RMSE: 15.9075\n",
      "Training fold 10/10 for Poly SVM...\n",
      "Fold 10 - MAE: 8.0602, MSE: 232.1979, RMSE: 15.2380\n",
      "Poly SVM Mean -> MAE: 8.1522, MSE: 239.7814, RMSE: 15.4832\n",
      "\n",
      "\n",
      "=== Cross-validating Linear SVM ===\n",
      "Training fold 1/10 for Linear SVM...\n",
      "Fold 1 - MAE: 9.9468, MSE: 373.9848, RMSE: 19.3387\n",
      "Training fold 2/10 for Linear SVM...\n",
      "Fold 2 - MAE: 9.6918, MSE: 357.8579, RMSE: 18.9171\n",
      "Training fold 3/10 for Linear SVM...\n",
      "Fold 3 - MAE: 9.7544, MSE: 374.2434, RMSE: 19.3454\n",
      "Training fold 4/10 for Linear SVM...\n",
      "Fold 4 - MAE: 9.7298, MSE: 365.1074, RMSE: 19.1078\n",
      "Training fold 5/10 for Linear SVM...\n",
      "Fold 5 - MAE: 9.8805, MSE: 374.0894, RMSE: 19.3414\n",
      "Training fold 6/10 for Linear SVM...\n",
      "Fold 6 - MAE: 9.6334, MSE: 347.2177, RMSE: 18.6338\n",
      "Training fold 7/10 for Linear SVM...\n",
      "Fold 7 - MAE: 9.4269, MSE: 348.4661, RMSE: 18.6672\n",
      "Training fold 8/10 for Linear SVM...\n",
      "Fold 8 - MAE: 9.5737, MSE: 341.6923, RMSE: 18.4849\n",
      "Training fold 9/10 for Linear SVM...\n",
      "Fold 9 - MAE: 9.8894, MSE: 398.4611, RMSE: 19.9615\n",
      "Training fold 10/10 for Linear SVM...\n",
      "Fold 10 - MAE: 9.6355, MSE: 362.0446, RMSE: 19.0275\n",
      "Linear SVM Mean -> MAE: 9.7162, MSE: 364.3165, RMSE: 19.0825\n",
      "\n",
      "\n",
      "=== Cross-validating RBF SVM ===\n",
      "Training fold 1/10 for RBF SVM...\n",
      "Fold 1 - MAE: 4.7235, MSE: 109.9095, RMSE: 10.4838\n",
      "Training fold 2/10 for RBF SVM...\n",
      "Fold 2 - MAE: 4.5142, MSE: 102.9543, RMSE: 10.1466\n",
      "Training fold 3/10 for RBF SVM...\n",
      "Fold 3 - MAE: 4.5152, MSE: 101.5952, RMSE: 10.0794\n",
      "Training fold 4/10 for RBF SVM...\n",
      "Fold 4 - MAE: 4.6604, MSE: 107.2756, RMSE: 10.3574\n",
      "Training fold 5/10 for RBF SVM...\n",
      "Fold 5 - MAE: 4.5653, MSE: 103.4979, RMSE: 10.1734\n",
      "Training fold 6/10 for RBF SVM...\n",
      "Fold 6 - MAE: 4.5145, MSE: 97.1322, RMSE: 9.8556\n",
      "Training fold 7/10 for RBF SVM...\n",
      "Fold 7 - MAE: 4.4099, MSE: 100.6166, RMSE: 10.0308\n",
      "Training fold 8/10 for RBF SVM...\n",
      "Fold 8 - MAE: 4.5517, MSE: 100.2945, RMSE: 10.0147\n",
      "Training fold 9/10 for RBF SVM...\n",
      "Fold 9 - MAE: 4.5405, MSE: 110.7455, RMSE: 10.5236\n",
      "Training fold 10/10 for RBF SVM...\n",
      "Fold 10 - MAE: 4.5272, MSE: 96.7594, RMSE: 9.8366\n",
      "RBF SVM Mean -> MAE: 4.5522, MSE: 103.0781, RMSE: 10.1502\n",
      "\n",
      "=== 10-Fold CV Results with PCA ===\n",
      "                         MAE         MSE       RMSE\n",
      "Model                                              \n",
      "KNN                 1.831616   17.304989   4.157839\n",
      "Random Forest       1.443446   10.462263   3.231661\n",
      "Decision Tree       1.778833   28.265591   5.306073\n",
      "MLP                 3.780326   35.770452   5.979112\n",
      "Linear Regression  11.091496  291.097964  17.057919\n",
      "Ridge Regression   11.091428  291.097963  17.057919\n",
      "Poly SVM            8.152189  239.781435  15.483222\n",
      "Linear SVM          9.716234  364.316472  19.082527\n",
      "RBF SVM             4.552250  103.078079  10.150192\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "# 3. Define models\n",
    "models = {\n",
    "    'KNN': make_pipeline(StandardScaler(), pca, KNeighborsRegressor()),\n",
    "    'Random Forest': make_pipeline(StandardScaler(), pca, RandomForestRegressor(random_state=42)),\n",
    "    'Decision Tree': make_pipeline(StandardScaler(), pca, DecisionTreeRegressor(random_state=42)),\n",
    "    'MLP': make_pipeline(StandardScaler(), pca, MLPRegressor(random_state=42, max_iter=500)),\n",
    "    'Linear Regression': make_pipeline(StandardScaler(), pca, LinearRegression()),\n",
    "    'Ridge Regression': make_pipeline(StandardScaler(), pca, Ridge(random_state=42)),\n",
    "    'Poly SVM': make_pipeline(StandardScaler(), pca, SVR(kernel='poly', degree=3, C=1, gamma='scale')),\n",
    "    'Linear SVM': make_pipeline(StandardScaler(), pca, LinearSVR(C=1.0, epsilon=0.1, max_iter=10000, random_state=42)),\n",
    "    'RBF SVM': make_pipeline(StandardScaler(), pca, SVR(kernel='rbf', C=1.0, gamma='scale')),\n",
    "}\n",
    "\n",
    "# 3. 10-Fold CV performance evaluation\n",
    "print(\"Starting 10-Fold cross-validation with PCA...\")\n",
    "kf_cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== Cross-validating {name} ===\")\n",
    "    mae_scores, mse_scores, rmse_scores = [], [], []\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf_cv.split(X_train_enc), 1):\n",
    "        print(f\"Training fold {fold}/10 for {name}...\")\n",
    "        X_tr, X_val = X_train_enc.iloc[train_idx], X_train_enc.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_pred = model.predict(X_val)\n",
    "        mae = mean_absolute_error(y_val, y_pred)\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae_scores.append(mae)\n",
    "        mse_scores.append(mse)\n",
    "        rmse_scores.append(rmse)\n",
    "        print(f\"Fold {fold} - MAE: {mae:.4f}, MSE: {mse:.4f}, RMSE: {rmse:.4f}\")\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'MAE': np.mean(mae_scores),\n",
    "        'MSE': np.mean(mse_scores),\n",
    "        'RMSE': np.mean(rmse_scores)\n",
    "    })\n",
    "    print(f\"{name} Mean -> MAE: {np.mean(mae_scores):.4f}, MSE: {np.mean(mse_scores):.4f}, RMSE: {np.mean(rmse_scores):.4f}\\n\")\n",
    "\n",
    "# 4. Summarize results in a table\n",
    "print(\"=== 10-Fold CV Results with PCA ===\")\n",
    "df_results = pd.DataFrame(results).set_index('Model')\n",
    "print(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dbfe73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training KNN on full training set and evaluating on test set ===\n",
      "KNN - Test MAE: 1.7241, MSE: 14.5774, RMSE: 3.8180\n",
      "\n",
      "=== Training Random Forest on full training set and evaluating on test set ===\n",
      "Random Forest - Test MAE: 1.2887, MSE: 7.7536, RMSE: 2.7845\n",
      "\n",
      "=== Training Decision Tree on full training set and evaluating on test set ===\n",
      "Decision Tree - Test MAE: 1.5801, MSE: 22.7053, RMSE: 4.7650\n",
      "\n",
      "=== Training MLP on full training set and evaluating on test set ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maya2\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP - Test MAE: 3.7018, MSE: 33.9297, RMSE: 5.8249\n",
      "\n",
      "=== Training Linear Regression on full training set and evaluating on test set ===\n",
      "Linear Regression - Test MAE: 11.0220, MSE: 271.3364, RMSE: 16.4723\n",
      "\n",
      "=== Training Ridge Regression on full training set and evaluating on test set ===\n",
      "Ridge Regression - Test MAE: 11.0220, MSE: 271.3361, RMSE: 16.4723\n",
      "\n",
      "=== Training Poly SVM on full training set and evaluating on test set ===\n",
      "Poly SVM - Test MAE: 7.9246, MSE: 218.7989, RMSE: 14.7919\n",
      "\n",
      "=== Training Linear SVM on full training set and evaluating on test set ===\n",
      "Linear SVM - Test MAE: 9.5284, MSE: 333.8083, RMSE: 18.2704\n",
      "\n",
      "=== Training RBF SVM on full training set and evaluating on test set ===\n",
      "RBF SVM - Test MAE: 4.4083, MSE: 92.3485, RMSE: 9.6098\n",
      "\n",
      "=== Test Set Results ===\n",
      "                    Test MAE    Test MSE  Test RMSE\n",
      "Model                                              \n",
      "KNN                 1.724081   14.577361   3.818031\n",
      "Random Forest       1.288728    7.753625   2.784533\n",
      "Decision Tree       1.580071   22.705250   4.765003\n",
      "MLP                 3.701752   33.929709   5.824921\n",
      "Linear Regression  11.022036  271.336386  16.472291\n",
      "Ridge Regression   11.021973  271.336144  16.472284\n",
      "Poly SVM            7.924602  218.798943  14.791854\n",
      "Linear SVM          9.528416  333.808330  18.270422\n",
      "RBF SVM             4.408309   92.348503   9.609813\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_cv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28mprint\u001b[39m(df_test)\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Merge CV and Test results for comparison\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m df_combined = \u001b[43mdf_cv\u001b[49m.join(df_test)\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== CV vs Test Comparison ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(df_combined)\n",
      "\u001b[31mNameError\u001b[39m: name 'df_cv' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# TEST SET EVALUATION\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "test_results = []\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== Training {name} on full training set and evaluating on test set ===\")\n",
    "    model.fit(X_train_enc, y_train)\n",
    "    y_pred_test = model.predict(X_test_enc)\n",
    "    \n",
    "    mae_test  = mean_absolute_error(y_test, y_pred_test)\n",
    "    mse_test  = mean_squared_error(y_test, y_pred_test)\n",
    "    rmse_test = np.sqrt(mse_test)\n",
    "    \n",
    "    test_results.append({\n",
    "        'Model': name,\n",
    "        'Test MAE': mae_test,\n",
    "        'Test MSE': mse_test,\n",
    "        'Test RMSE': rmse_test\n",
    "    })\n",
    "    print(f\"{name} - Test MAE: {mae_test:.4f}, MSE: {mse_test:.4f}, RMSE: {rmse_test:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# visualize comparison side by side\n",
    "# df_combined.plot(kind='bar', figsize=(14, 7), color=['lightblue', 'salmon'])\n",
    "# plt.title('CV vs Test Error Comparison')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b51fc558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Test Set Results ===\n",
      "                    Test MAE    Test MSE  Test RMSE\n",
      "Model                                              \n",
      "KNN                 1.724081   14.577361   3.818031\n",
      "Random Forest       1.288728    7.753625   2.784533\n",
      "Decision Tree       1.580071   22.705250   4.765003\n",
      "MLP                 3.701752   33.929709   5.824921\n",
      "Linear Regression  11.022036  271.336386  16.472291\n",
      "Ridge Regression   11.021973  271.336144  16.472284\n",
      "Poly SVM            7.924602  218.798943  14.791854\n",
      "Linear SVM          9.528416  333.808330  18.270422\n",
      "RBF SVM             4.408309   92.348503   9.609813\n",
      "\n",
      "=== CV vs Test Comparison ===\n",
      "                         MAE         MSE       RMSE   Test MAE    Test MSE  \\\n",
      "Model                                                                        \n",
      "KNN                 1.831616   17.304989   4.157839   1.724081   14.577361   \n",
      "Random Forest       1.443446   10.462263   3.231661   1.288728    7.753625   \n",
      "Decision Tree       1.778833   28.265591   5.306073   1.580071   22.705250   \n",
      "MLP                 3.780326   35.770452   5.979112   3.701752   33.929709   \n",
      "Linear Regression  11.091496  291.097964  17.057919  11.022036  271.336386   \n",
      "Ridge Regression   11.091428  291.097963  17.057919  11.021973  271.336144   \n",
      "Poly SVM            8.152189  239.781435  15.483222   7.924602  218.798943   \n",
      "Linear SVM          9.716234  364.316472  19.082527   9.528416  333.808330   \n",
      "RBF SVM             4.552250  103.078079  10.150192   4.408309   92.348503   \n",
      "\n",
      "                   Test RMSE  \n",
      "Model                         \n",
      "KNN                 3.818031  \n",
      "Random Forest       2.784533  \n",
      "Decision Tree       4.765003  \n",
      "MLP                 5.824921  \n",
      "Linear Regression  16.472291  \n",
      "Ridge Regression   16.472284  \n",
      "Poly SVM           14.791854  \n",
      "Linear SVM         18.270422  \n",
      "RBF SVM             9.609813  \n"
     ]
    }
   ],
   "source": [
    "# Summarize Test results\n",
    "df_test = pd.DataFrame(test_results).set_index('Model')\n",
    "print(\"\\n=== Test Set Results ===\")\n",
    "print(df_test)\n",
    "\n",
    "\n",
    "# Merge CV and Test results for comparison\n",
    "df_combined = df_results.join(df_test)\n",
    "print(\"\\n=== CV vs Test Comparison ===\")\n",
    "print(df_combined)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
